# DiSCVAE

Disentangled Sequence Clustering Variational Autoencoder (DiSCVAE) -- a deep generative model that simultaneously clusters and disentangles latent representations of sequences. This repository contains code for the DiSCVAE applied to two synthetic video datasets: [Moving MNIST](http://www.cs.toronto.edu/~nitish/unsupervised_video/) and [Sprites](https://lpc.opengameart.org/).

The following paper describes its formulation and experimentation on the aforementioned datasets, as well as its application to the problem of human intention inference in a robotic wheelchair setting:

**<a href="https://arxiv.org/abs/2101.09500">Disentangled Sequence Clustering for Human Intention Inference</a>**
<br>
[Mark Zolotas](https://markzolotas.com/), [Yiannis Demiris](https://www.imperial.ac.uk/people/y.demiris)

## Directory Layout

- `bin`: A set of shell scripts illustrating examples of how to train and evaluate different models on the chosen datasets.
- `checkpoints`: Checkpoint states of trained models and the directory for storing evaluated results (quantitative and qualitative).
- `data`: Where the Moving MNIST dataset (`.npz` format) and the Sprites dataset (`npy/` directory of `.npz` files) should be stored.
- `scripts`: Python modules related to running the DiSCVAE, as well as other sequential generative models. 

## Dependencies

All development took place using Python 3.7 and TensorFlow 2.1 coupled with its [Probability](https://www.tensorflow.org/probability) library. GPU toolkit dependencies are CUDA 10.1 plus cuDNN 7.6.5. The majority of remaining dependencies can be installed as such:
```
pip install -r requirements.txt
```

## Dataset Preparation

The Moving MNIST dataset utilised for this work can be generated using `scripts/data/moving_mnist.py`. This can be run from the top-level directory:
```
python scripts/data/moving_mnist.py --dataset_path ./data --filename moving_mnist
```

Likewise, the Sprites dataset is generated by following the instructions from [this repository](https://github.com/YingzhenLi/Sprites) and creating a folder of `.npy` files. This folder can then be moved to the `data` directory and `scripts/data/lpc.py` will load the dataset.

## Training and Evaluation

The shell scripts in the `bin` directory contain numerous configurations for training different models on the two datasets. Before running these scripts, please change the `WS_DIR` environment variable to your corresponding workspace directory.

For example, the following will train the DiSCVAE on MovingMNIST across 10 random seeds:
```
./bin/run_discvae_train.sh 
```

Or the [VRNN](https://arxiv.org/abs/1506.02216) can be trained on Sprites using:
```
./bin/run_vrnn_train.sh 
```

Similarly, the evaluation scripts can be run as follows:
```
./bin/run_discvae_eval.sh 
```